{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Evaluation Criteria\n",
    "\n",
    "In this example, we will see how to create a custom metric.\n",
    "\n",
    "We will create a metric that evaluates whether a user query is decomposed into sub-queries, covering all the angles of the original query to retrieve all the necessary information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the metric\n",
    "\n",
    "`flow-judge` makes it easy to create custom metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_judge.metrics import CustomMetric, RubricItem\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Define the criteria\n",
    "evaluation_criteria = \"\"\"Do the generated sub-queries provide sufficient breadth to cover all aspects of the main query?\"\"\"\n",
    "\n",
    "# Define the rubric using RubricItem's\n",
    "rubric = [\n",
    "    RubricItem(\n",
    "        score=1,\n",
    "        description=\"The sub-queries lack breadth and fail to address multiple important aspects of the main query. They are either too narrow, focusing on only one or two dimensions of the question, or they diverge significantly from the main query's intent. Using these sub-queries alone would result in a severely limited exploration of the topic.\"),\n",
    "    RubricItem(\n",
    "        score=2,\n",
    "        description=\"The sub-queries cover some aspects of the main query but lack comprehensive breadth. While they touch on several dimensions of the question, there are still noticeable gaps in coverage. Some important facets of the main query are either underrepresented or missing entirely. Answering these sub-queries would provide a partial, but not complete, exploration of the main topic.\"),\n",
    "    RubricItem(\n",
    "        score=3,\n",
    "        description=\"The sub-queries demonstrate excellent breadth, effectively covering all major aspects of the main query. They break down the main question into a diverse set of dimensions, ensuring a comprehensive exploration of the topic. Each significant facet of the main query is represented in the sub-queries, allowing for a thorough and well-rounded investigation of the subject matter.\"),\n",
    "]\n",
    "\n",
    "# We need to define the required inputs and output for the metric\n",
    "required_inputs = [\"query\"]\n",
    "required_output = \"sub_queries\"\n",
    "\n",
    "# Create the metric\n",
    "sub_query_coverage = CustomMetric(\n",
    "    name=\"sub-query-coverage\",\n",
    "    criteria=evaluation_criteria,\n",
    "    rubric=rubric,\n",
    "    required_inputs=required_inputs,\n",
    "    required_output=required_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we quickly created a custom metric that will instruct the model to evaluate according to the criteria and rubric we set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomMetric(name='sub-query-coverage', criteria='Do the generated sub-queries provide sufficient breadth to cover all aspects of the main query?', rubric=[RubricItem(score=1, description=\"The sub-queries lack breadth and fail to address multiple important aspects of the main query. They are either too narrow, focusing on only one or two dimensions of the question, or they diverge significantly from the main query's intent. Using these sub-queries alone would result in a severely limited exploration of the topic.\"), RubricItem(score=2, description='The sub-queries cover some aspects of the main query but lack comprehensive breadth. While they touch on several dimensions of the question, there are still noticeable gaps in coverage. Some important facets of the main query are either underrepresented or missing entirely. Answering these sub-queries would provide a partial, but not complete, exploration of the main topic.'), RubricItem(score=3, description='The sub-queries demonstrate excellent breadth, effectively covering all major aspects of the main query. They break down the main question into a diverse set of dimensions, ensuring a comprehensive exploration of the topic. Each significant facet of the main query is represented in the sub-queries, allowing for a thorough and well-rounded investigation of the subject matter.')], required_inputs=['query'], required_output='sub_queries')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_query_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running evaluations with the custom metric\n",
    "\n",
    "Now, we just need to initialize the judge with our custom metric and run the evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-20 15:53:15 awq_marlin.py:89] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.\n",
      "WARNING 09-20 15:53:15 config.py:378] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 09-20 15:53:15 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='flowaicom/Flow-Judge-v0.1-AWQ', speculative_config=None, tokenizer='flowaicom/Flow-Judge-v0.1-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq_marlin, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=flowaicom/Flow-Judge-v0.1-AWQ, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=False)\n",
      "INFO 09-20 15:53:15 model_runner.py:915] Starting to load model flowaicom/Flow-Judge-v0.1-AWQ...\n",
      "INFO 09-20 15:53:16 weight_utils.py:236] Using model weights format ['*.safetensors']\n",
      "INFO 09-20 15:53:16 weight_utils.py:280] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517b66e895064f31b014f0c18d8cd09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-20 15:53:17 model_runner.py:926] Loading model weights took 2.1861 GB\n",
      "INFO 09-20 15:53:19 gpu_executor.py:122] # GPU blocks: 3080, # CPU blocks: 682\n"
     ]
    }
   ],
   "source": [
    "from flow_judge.models.model_factory import ModelFactory\n",
    "from flow_judge.flow_judge import EvalInput, FlowJudge\n",
    "\n",
    "# Create a model using ModelFactory\n",
    "model = ModelFactory.create_model(\"Flow-Judge-v0.1-AWQ\")\n",
    "\n",
    "# Initialize the judge\n",
    "judge = FlowJudge(metric=sub_query_coverage, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.44s/it, est. speed input: 132.19 toks/s, output: 47.87 toks/s]\n"
     ]
    }
   ],
   "source": [
    "# Sample to evaluate\n",
    "\n",
    "query = \"I placed an order for a custom-built gaming PC (order #AC-789012) two weeks ago, but the estimated delivery date has changed twice since then. Originally it was supposed to arrive yesterday, then it got pushed to next week, and now the tracking page shows 'Status: Processing' with no delivery estimate at all. I've tried calling customer service, but after waiting on hold for an hour, I was told to check the website. Can you please look into this and explain what's causing the delays, when I can realistically expect my order to arrive, and whether I'm eligible for any kind of compensation or expedited shipping given these repeated delays? I'm especially concerned because I need this computer for an upcoming gaming tournament I'm participating in next month.\"\n",
    "sub_queries = \"What is the current shipping status of my order? When will my computer arrive?\"\n",
    "\n",
    "# bad decomposition\n",
    "eval_input = EvalInput(\n",
    "    inputs=[\n",
    "        {\"query\": query}\n",
    "    ],\n",
    "    output={\"sub_queries\": sub_queries}\n",
    ")\n",
    "\n",
    "# Run the evaluation\n",
    "result = judge.evaluate(eval_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__Feedback:__\n",
       "The generated sub-queries demonstrate excellent breadth and effectively cover all major aspects of the main query. The first sub-query, \"What is the current shipping status of my order?\" directly addresses the customer's concern about the changing delivery dates and the current 'Status: Processing' message on the tracking page. This sub-query ensures that the customer's immediate concern about the order's location is addressed.\n",
       "\n",
       "The second sub-query, \"When will my computer arrive?\" tackles the customer's request for a realistic delivery estimate, which is crucial given the repeated delays and the customer's urgent need for the gaming PC. This sub-query aims to provide the specific information the customer is seeking regarding the expected arrival time of their order.\n",
       "\n",
       "Furthermore, the sub-queries implicitly cover the customer's concern about potential compensation or expedited shipping by addressing the current status and expected delivery time. While not explicitly mentioned, these aspects are inherently part of understanding the order's status and delivery timeline.\n",
       "\n",
       "The sub-queries also touch on the customer's need for the computer for an upcoming gaming tournament, as addressing the delivery status and providing a realistic arrival time would be directly relevant to the customer's situation.\n",
       "\n",
       "Overall, the sub-queries break down the main question into a diverse set of dimensions, ensuring a comprehensive exploration of the topic. Each significant facet of the main query is represented, allowing for a thorough and well-rounded investigation of the subject matter.\n",
       "\n",
       "__Score:__\n",
       "3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the result\n",
    "display(Markdown(f\"__Feedback:__\\n{result.feedback}\\n\\n__Score:__\\n{result.score}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.74s/it, est. speed input: 175.59 toks/s, output: 46.46 toks/s]\n"
     ]
    }
   ],
   "source": [
    "# Good decomposition\n",
    "\n",
    "sub_queries = \"\"\"1. What is the current status of order #AC-789012, and why has it changed from the original estimated delivery date?\n",
    "2. What specific factors are causing the delays in processing and shipping this custom-built gaming PC?\n",
    "3. Based on the current situation, when can the customer realistically expect the order to arrive?\n",
    "4. Given the repeated delays and changes in estimated delivery, what compensation options (if any) are available to the customer?\n",
    "5. Is expedited shipping an option at this point, and if so, how would it affect the delivery timeline?\n",
    "6. How can the urgency of this order be communicated and prioritized, considering the customer's upcoming gaming tournament next month?\n",
    "7. What steps has customer service already taken to address this issue, and what additional actions can be taken to resolve it?\n",
    "8. How can the customer receive more frequent and accurate updates about their order status going forward?\"\"\"\n",
    "\n",
    "eval_input = EvalInput(\n",
    "    inputs=[\n",
    "        {\"query\": query}\n",
    "    ],\n",
    "    output={\"sub_queries\": sub_queries}\n",
    ")\n",
    "\n",
    "# Run the evaluation\n",
    "result = judge.evaluate(eval_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__Feedback:__\n",
       "The generated sub-queries demonstrate excellent breadth, effectively covering all major aspects of the main query. Each significant facet of the main query is represented in the sub-queries, ensuring a comprehensive exploration of the topic.\n",
       "\n",
       "The sub-queries address the following key points from the main query:\n",
       "\n",
       "1. Current status and reasons for delivery date changes\n",
       "2. Specific factors causing delays\n",
       "3. Realistic expected delivery time\n",
       "4. Compensation options due to delays\n",
       "5. Availability of expedited shipping\n",
       "6. Prioritization of the order considering the upcoming tournament\n",
       "7. Actions taken by customer service and potential additional steps\n",
       "8. Improved communication and updates for the customer\n",
       "\n",
       "These sub-queries break down the main question into diverse dimensions, ensuring a thorough investigation of the subject matter. They cover the technical aspects of the order, the customer service response, potential solutions, and future improvements. This comprehensive approach allows for a well-rounded exploration of the topic, addressing all major concerns raised in the original query.\n",
       "\n",
       "The sub-queries are well-structured and cover all important aspects without straying from the main query's intent. They provide a solid foundation for investigating and resolving the customer's issues, ensuring that no significant part of the original query is overlooked.\n",
       "\n",
       "__Score:__\n",
       "3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the result\n",
    "display(Markdown(f\"__Feedback:__\\n{result.feedback}\\n\\n__Score:__\\n{result.score}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.70s/it, est. speed input: 158.41 toks/s, output: 45.84 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Feedback:__\n",
       "The generated sub-queries demonstrate a good attempt to cover various aspects of the main query, but they fall short of providing comprehensive breadth. The sub-queries address several key points raised in the main query, such as the current status of the order, reasons for delivery date changes, expected arrival time, and the possibility of expediting the order. These are directly relevant to the customer's concerns.\n",
       "\n",
       "However, there are noticeable gaps in coverage. The sub-queries fail to address the customer's repeated attempts to contact customer service and the specific instructions given by customer service. They also don't address the customer's concern about eligibility for compensation due to repeated delays. While the sub-queries do touch on the need for better customer service support, they don't specifically address the customer's frustration with the support experience.\n",
       "\n",
       "Additionally, the sub-queries include some that are not directly relevant to the main query, such as questions about store hours and the name of the person responsible for the company. These do not contribute to addressing the customer's specific concerns about the order and its delays.\n",
       "\n",
       "Overall, while the sub-queries cover some important aspects of the main query, they miss several key points and include some irrelevant questions, preventing a truly comprehensive exploration of the topic.\n",
       "\n",
       "__Score:__\n",
       "2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Okish decomposition\n",
    "\n",
    "sub_queries = \"\"\"1. What is the current status of order #AC-7892?\n",
    "Why has the delivery date changed multiple times?\n",
    "When will the custom-built gaming PC actually arrive?\n",
    "What are your store hours on weekends?\n",
    "How can I get better customer service support?\n",
    "8. Can the order be expedited?\n",
    "9. What is the name of the person that is responsible for the company?\n",
    "\"\"\"\n",
    "\n",
    "eval_input = EvalInput(\n",
    "    inputs=[\n",
    "        {\"query\": query}\n",
    "    ],\n",
    "    output={\"sub_queries\": sub_queries}\n",
    ")\n",
    "\n",
    "# Run the evaluation\n",
    "result = judge.evaluate(eval_input)\n",
    "# Display the result\n",
    "display(Markdown(f\"__Feedback:__\\n{result.feedback}\\n\\n__Score:__\\n{result.score}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
